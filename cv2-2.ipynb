{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d717a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33da9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To read an image\n",
    "img = cv2.imread('amjad.jpg')\n",
    "# To display image windows name and variable stored name\n",
    "cv2.imshow('test',img)\n",
    "\n",
    "# To hold an image\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de92473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To read an image in BGR in color mode no needed it automatically show \n",
    "img = cv2.imread('amjad.jpg',cv2.IMREAD_COLOR)\n",
    "# To display image windows name and variable stored name\n",
    "cv2.imshow('test',img)\n",
    "\n",
    "# To hold an image\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a99c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display an image ina gray scale image\n",
    "import cv2\n",
    "\n",
    "# To read an image\n",
    "img = cv2.imread('amjad.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "# To display image windows name and variable stored name\n",
    "cv2.imshow('test',img)\n",
    "\n",
    "# To hold an image\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96e1eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display an image without missing any data\n",
    "import cv2\n",
    "\n",
    "# To read an image\n",
    "img = cv2.imread('amjad.jpg',cv2.IMREAD_UNCHANGED)\n",
    "# To display image windows name and variable stored name\n",
    "cv2.imshow('test',img)\n",
    "\n",
    "# To hold an image\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afbedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check camera\n",
    "import cv2\n",
    "\n",
    "# instance of video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# This will return wether our camera is opened or not\n",
    "Opened = cap.isOpened()\n",
    "\n",
    "if(Opened):\n",
    "    while(cap.isOpened()):\n",
    "        # ret will return bollen values wether the frame is wrritened or not\n",
    "        ret, frame = cap.read()\n",
    "        if(ret==True):\n",
    "            cv2.imshow('winner', frame)\n",
    "            # here esc value is 27\n",
    "            if(cv2.waitKey(2)==27):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba98baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames are 30.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "# To check camera height and width AND FRAME PER SEC\n",
    "import cv2\n",
    "\n",
    "# instance of video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# This will return wether our camera is opened or not\n",
    "Opened = cap.isOpened()\n",
    "\n",
    "# To find the height of an image\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "# To find frame per sec\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Frames are {}\".format(fps))\n",
    "print(height)\n",
    "\n",
    "if(Opened):\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        # ret will return bollen values wether the frame is wrritened or not\n",
    "        ret, frame = cap.read()\n",
    "        if(ret==True):\n",
    "            cv2.imshow('winner', frame)\n",
    "            # here esc value is 27\n",
    "            if(cv2.waitKey(2)==27):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03ef13",
   "metadata": {},
   "source": [
    "## Codec : For writing and reading for compresed video\n",
    "* To read compresed video\n",
    "* To read write compresed video\n",
    "* syntax : fourcc(x1, x2, x3, x4) or fourcc(*'MJPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772f374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames are 30.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "# To check camera height and width AND FRAME PER SEC\n",
    "import cv2\n",
    "\n",
    "# instance of video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# This will return wether our camera is opened or not\n",
    "Opened = cap.isOpened()\n",
    "\n",
    "# To find frame per sec\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "# To find the height of an image\n",
    "out = cv2.VideoWriter('amjad4.avi',fourcc,fps,(int(width),int(height)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Frames are {}\".format(fps))\n",
    "print(height)\n",
    "\n",
    "if(Opened):\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        # ret will return bollen values wether the frame is wrritened or not\n",
    "        ret, frame = cap.read()\n",
    "        if(ret==True):\n",
    "            cv2.imshow('winner', frame)\n",
    "            # here esc value is 27\n",
    "            if(cv2.waitKey(2)==27):\n",
    "                break\n",
    "                \n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7e3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of frames are : 0.0\n",
      "FPS is: 0.0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# resize the frame\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(frame)\n\u001b[0;32m     32\u001b[0m frame_index \u001b[38;5;241m=\u001b[39m frame_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('amjad4.mp4')\n",
    "\n",
    "#Properties of video\n",
    "# Total no of videos\n",
    "frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "#frames per second of video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width =  cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "#intilizing output writer for video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MPJG')\n",
    "out = cv2.VideoWriter('reversed.avi',fourcc,fps,(int(width*0.5),int(height*0.5)))\n",
    "\n",
    "print(\"no.of frames are : {}\".format(frames))\n",
    "print(\"FPS is: {}\".format(fps))\n",
    "\n",
    "frame_index = frames-1\n",
    "\n",
    "if(Opened):\n",
    "    \n",
    "    while(frame_index!=0):\n",
    "        # ret will return bollen values wether the frame is wrritened or not\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,frame_index)\n",
    "        ret, frame = cap.read()\n",
    "        # resize the frame\n",
    "        frame = cv2.resize(frame,(int(width*0.5),int(height*0.5)))\n",
    "        out.write(frame)\n",
    "        frame_index = frame_index-1\n",
    "        \n",
    "        if(frame_index%100==0):\n",
    "            print(frame_index)\n",
    "                \n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3e44f",
   "metadata": {},
   "source": [
    "* Drawing lines\n",
    "* Drawing Shapes\n",
    "* Poligons\n",
    "* placing text on the cameras\n",
    "* Alised and Anti alised lines\n",
    "* subpixel accuracy\n",
    "* shift parameter\n",
    "* Alised line : pixel to pixel connected it doesn't have any blur in the line\n",
    "* Antialiasing : pixel to pixel connected but having some blure at the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26547820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Creating a canvas 500x500 (three channels)\n",
    "canvas = np.zeros((500,500,3))\n",
    "\n",
    "# Drawing a line\n",
    "# cv2.line(img,point1,point2,color,thickness,linetype)\n",
    "# linetype : they are three types : 1. LINE_4 , 2.lINE_8, 3.LINE_AA \n",
    "# 1. LINE_4 , 2.lINE_8 : these are alised line build with \"bresenham algo\"\n",
    "# 3. LINE_AA : these are antialising these are build with \"Gausian filtering\"\n",
    "\n",
    "cv2.line(canvas,(0,0),(100,100),(0,255,0),2,cv2.LINE_4)\n",
    "cv2.line(canvas,(0,20),(120,120),(0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "# Drawing a rectangle\n",
    "cv2.rectangle(canvas,(200,200),(250,270),(0,0,255),-1)\n",
    "\n",
    "# Drawing circle cv2.circle(img,center,raidus,color)\n",
    "cv2.circle(canvas,(250,250),10,(255,0,0),3)\n",
    "\n",
    "# Drawing Arrowed line\n",
    "cv2.arrowedLine(canvas, (400,400),(400,500),(255,255,255),tipLength=0.3)\n",
    "\n",
    "# Showing the canvas\n",
    "cv2.imshow('window',canvas)\n",
    "cv2.waitKey(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598178c5",
   "metadata": {},
   "source": [
    "#### Polygon_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2fe8058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Making a empty Black canvas\n",
    "canvas = np.zeros((300,300,3))\n",
    "\n",
    "# required points we need to join\n",
    "pts = np.array([[25,5],[220,80],[280,80],[100,100],[250,250]],np.int32)\n",
    "\n",
    "# reshape the points to shape (number_vertex, 1,2)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "\n",
    "# Drawa this polygon\n",
    "# Here bolean true and false determine if the figure is closed\n",
    "cv2.polylines(canvas,[pts],False,(0,255,0),3)\n",
    "cv2.polylines(canvas,[pts],True,(0,255,0),3)\n",
    "\n",
    "\n",
    "# Showing the canvas\n",
    "cv2.imshow('window',canvas)\n",
    "cv2.waitKey(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ee426",
   "metadata": {},
   "source": [
    "### Text fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68fab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "canvas = np.zeros((800,500))\n",
    "\n",
    "# List of fonts they are 8 Fonts\n",
    "fonts = [cv2.FONT_HERSHEY_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        cv2.FONT_HERSHEY_PLAIN,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_TRIPLEX,\n",
    "        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_SIMPLEX]\n",
    "\n",
    "position = (10,30)\n",
    "for i in range(0,8):\n",
    "    cv2.putText(canvas,\"This is opencv!\", position,fonts[i],1.1,(255,255,255),2)\n",
    "    position = (position[0], position[1] + 40)\n",
    "    cv2.putText(canvas, \"this is opencv!\".lower(),position,fonts[i],1.1,(255,255,255),2)\n",
    "    position = (position[0],position[1] + 40)\n",
    "    \n",
    "# Displaying the canvas\n",
    "cv2.imshow('window',canvas)\n",
    "cv2.waitKey(20)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8353a15",
   "metadata": {},
   "source": [
    "### Transforms : They are 3-types\n",
    "* 1. Euclidean\n",
    "* 2. Affine\n",
    "* 3. Projective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5677e",
   "metadata": {},
   "source": [
    "### Bluring an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18c3571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# import an image\n",
    "img = cv2.imread('amjad.jpg')\n",
    "\n",
    "# Appling the filters\n",
    "# Applying kernels\n",
    "kernel_identity = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "\n",
    "#Applying 3* kernel and / means normalising, if we wont do it gets blured\n",
    "kernel_3 = np.ones((3,3),dtype=np.float32) / 9.0\n",
    "\n",
    "#Appling 11*11 kernel\n",
    "kernel_11 = np.ones((11,11),dtype=np.float32) /121.0\n",
    "\n",
    "# Appling the filters source ddepth, kernel\n",
    "# To check the depth = cv2.cv_165, .. or -1\n",
    "out1 = cv2.filter2D(img,-1,kernel_identity)\n",
    "out2 = cv2.filter2D(img,-1,kernel_3)\n",
    "out3 = cv2.filter2D(img,-1,kernel_11)\n",
    "\n",
    "cv2.imshow('window',out1)\n",
    "cv2.imshow('window1',out2)\n",
    "cv2.imshow('window2',out3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48baf40",
   "metadata": {},
   "source": [
    "### Motion Bluring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d5a82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('amjad.jpg')\n",
    "\n",
    "# Size of the kernel\n",
    "size = 15\n",
    "\n",
    "kernel = np.zeros((size,size))\n",
    "kernel[int((size-1)/2),:] = np.ones(size)\n",
    "kernel = kernel/size\n",
    "\n",
    "output = cv2.filter2D(img, -1, kernel)\n",
    "cv2.imshow('window',output)\n",
    "cv2.imshow('window1',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa1671",
   "metadata": {},
   "source": [
    "## To Preprocessing image\n",
    "* Kernel Blur\n",
    "* Box Filtering\n",
    "* blur() function\n",
    "* gaussian blur\n",
    "* Median Blur\n",
    "* Bilateral Filtering\n",
    "* Sharpening image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a21445",
   "metadata": {},
   "source": [
    "## 1. Kernel Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd3bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('amjad.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740fef67",
   "metadata": {},
   "source": [
    "## 2.Box Filtering and Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafdaa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('amjad.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a71f6",
   "metadata": {},
   "source": [
    "### 3.Gaussian Bluring\n",
    "* It is far better than doing direct blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5b018a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('amjad.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "# Gaussian Bluring\n",
    "#GaussianBlur(source,kernelsize(ksize),sigmax)\n",
    "#sigmax = this is the standered deviation in x function\n",
    "# if we took a value the normalized graph get ore flatten\n",
    "output_gaus = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "cv2.imshow('GaussianBlur',output_gaus)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42d8a1",
   "metadata": {},
   "source": [
    "### 5. Median Blur\n",
    "* Median blur replace pixel value with the median of all values lying in kernel area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00f9b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('amjad.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "# Gaussian Bluring\n",
    "#GaussianBlur(source,kernelsize(ksize),sigmax)\n",
    "#sigmax = this is the standered deviation in x function\n",
    "# if we took a value the normalized graph get ore flatten\n",
    "output_gaus = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "# Median Blur\n",
    "# in median having kernel size needs to give 1 beacuse it will automatic square\n",
    "output_med = cv2.medianBlur(img,5)\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "cv2.imshow('GaussianBlur',output_gaus)\n",
    "cv2.imshow('medianBlur',output_med)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a51ea",
   "metadata": {},
   "source": [
    "### 6. Bilateral Filtering\n",
    "* Reduction of Noise\n",
    "* Preserving edges of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d2415d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('amjad.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "# Gaussian Bluring\n",
    "#GaussianBlur(source,kernelsize(ksize),sigmax)\n",
    "#sigmax = this is the standered deviation in x function\n",
    "# if we took a value the normalized graph get ore flatten\n",
    "output_gaus = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "# Median Blur\n",
    "# in median having kernel size needs to give 1 beacuse it will automatic square\n",
    "output_med = cv2.medianBlur(img,5)\n",
    "\n",
    "# bilateralFilter(source,distance(how much diameter we need to consider),sigmacolor(S.d of color),sigmaspace())\n",
    "# Sigmacolor if we increase the sigma color the boundries will extract near color and makes into single color\n",
    "output_bil = cv2.bilateralFilter(img,5,6,6)\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "cv2.imshow('GaussianBlur',output_gaus)\n",
    "cv2.imshow('medianBlur',output_med)\n",
    "cv2.imshow('bilateral',output_bil)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc40821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('gray.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "# Gaussian Bluring\n",
    "#GaussianBlur(source,kernelsize(ksize),sigmax)\n",
    "#sigmax = this is the standered deviation in x function\n",
    "# if we took a value the normalized graph get ore flatten\n",
    "output_gaus = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "# Median Blur\n",
    "# in median having kernel size needs to give 1 beacuse it will automatic square\n",
    "output_med = cv2.medianBlur(img,5)\n",
    "\n",
    "# bilateralFilter(source,distance(how much diameter we need to consider),sigmacolor(S.d of color),sigmaspace())\n",
    "# Sigmacolor if we increase the sigma color the boundries will extract near color and makes into single color\n",
    "output_bil = cv2.bilateralFilter(img,5,6,6)\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "cv2.imshow('GaussianBlur',output_gaus)\n",
    "cv2.imshow('medianBlur',output_med)\n",
    "cv2.imshow('bilateral',output_bil)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856f06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image from computer and taking dimensions\n",
    "img = cv2.imread('noisy.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# Kernel Blurring using filter2D()\n",
    "# creating 25*25 kernel and dividin to normalizing\n",
    "kernel_25 = np.ones((25,25),np.float32) / 625.0\n",
    "# output appling filter2D(source,ddepth,kernel)\n",
    "output_kernel = cv2.filter2D(img,-1,kernel_25)\n",
    "\n",
    "# BoxFiltering and Blur function and bluring\n",
    "output_blur = cv2.blur(img,(25,25))\n",
    "#Box filterning(source,ddepth,kernel,normalize = False)\n",
    "#Here we are not doing an normalization\n",
    "output_box = cv2.boxFilter(img,-1,(5,5),normalize=False)\n",
    "# Here we dont do normalize its almost White\n",
    "\n",
    "# Gaussian Bluring\n",
    "#GaussianBlur(source,kernelsize(ksize),sigmax)\n",
    "#sigmax = this is the standered deviation in x function\n",
    "# if we took a value the normalized graph get ore flatten\n",
    "output_gaus = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "# Median Blur\n",
    "# in median having kernel size needs to give 1 beacuse it will automatic square\n",
    "output_med = cv2.medianBlur(img,5)\n",
    "\n",
    "# bilateralFilter(source,distance(how much diameter we need to consider),sigmacolor(S.d of color),sigmaspace())\n",
    "# Sigmacolor if we increase the sigma color the boundries will extract near color and makes into single color\n",
    "output_bil = cv2.bilateralFilter(img,5,6,6)\n",
    "\n",
    "cv2.imshow('kernelBlur', output_kernel)\n",
    "cv2.imshow('blur',output_blur)\n",
    "cv2.imshow('BoxFilter',output_box)\n",
    "cv2.imshow('GaussianBlur',output_gaus)\n",
    "cv2.imshow('medianBlur',output_med)\n",
    "cv2.imshow('bilateral',output_bil)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303e1de",
   "metadata": {},
   "source": [
    "### Image sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1c78d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('noisy.jpg')\n",
    "\n",
    "# gass_blur = cv2.GaussianBlur(img,(7,7),2)\n",
    "gass_blur = cv2.GaussianBlur(img,(7,7),2)\n",
    "\n",
    "\n",
    "# Sharpening using add weighted\n",
    "#addweighted(source,source1*alpha,source2,betta,gama)\n",
    "#here: source1*alpha + source2*beta +gamma == 1\n",
    "# if we increase the intensity what will happend\n",
    "shar1 = cv2.addWeighted(img, 1.5, gass_blur, -0.5,0) # == 1\n",
    "shar2 = cv2.addWeighted(img, 3.5, gass_blur, -2.5,0) # == 1\n",
    "shar3 = cv2.addWeighted(img, 7.5, gass_blur, -6.5,0) # == 1\n",
    "\n",
    "# Showing the sharpend images\n",
    "cv2.imshow('shar1',shar1)\n",
    "cv2.imshow('shar2',shar2)\n",
    "cv2.imshow('shar3',shar3)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ce558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
